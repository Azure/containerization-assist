name: CI Pipeline

on:
  pull_request:
    branches: [ main ]
  push:
    branches: [ main ]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Quick validation and path detection
  setup:
    name: Setup & Path Detection
    runs-on: ubuntu-latest
    outputs:
      test-mcp: ${{ steps.detect-paths.outputs.test_mcp }}
      test-cli: ${{ steps.detect-paths.outputs.test_cli }}
      go-cache-key: ${{ steps.cache-keys.outputs.go-cache-key }}
      tools-cache-key: ${{ steps.cache-keys.outputs.tools-cache-key }}
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        
    - name: Detect changed paths
      id: detect-paths
      run: |
        if [ "${{ github.event_name }}" = "pull_request" ]; then
          echo "üîç Detecting changes for PR #${{ github.event.number }}"
          
          changed_files=$(git diff --name-only ${{ github.event.pull_request.base.sha }}..HEAD)
          echo "üìù Changed files: $(echo "$changed_files" | wc -l) total"
          
          # Check for MCP changes (cmd/mcp-server/, pkg/common/, pkg/core/, pkg/mcp/)
          mcp_count=$(echo "$changed_files" | grep -E "^(cmd/mcp-server/|pkg/(common|core|mcp)/)" | wc -l)
          echo "test_mcp=$([ $mcp_count -gt 0 ] && echo "true" || echo "false")" >> $GITHUB_OUTPUT
          
          # Check for CLI changes (cmd/*.go, pkg/ai/, pkg/core/, pkg/common/, pkg/pipeline/)
          cli_count=$(echo "$changed_files" | grep -E "^(cmd/(cmd|clients|generate|setup)\.go|pkg/(ai|core|common|pipeline)/)" | wc -l)
          echo "test_cli=$([ $cli_count -gt 0 ] && echo "true" || echo "false")" >> $GITHUB_OUTPUT
          
          echo "MCP changes: $([ $mcp_count -gt 0 ] && echo "yes ($mcp_count files)" || echo "no")"
          echo "CLI changes: $([ $cli_count -gt 0 ] && echo "yes ($cli_count files)" || echo "no")"
        else
          echo "test_mcp=true" >> $GITHUB_OUTPUT
          echo "test_cli=true" >> $GITHUB_OUTPUT
          echo "Non-PR event: testing all packages"
        fi
        
    - name: Generate cache keys
      id: cache-keys
      run: |
        echo "go-cache-key=${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}" >> $GITHUB_OUTPUT
        echo "tools-cache-key=${{ runner.os }}-quality-tools-v3" >> $GITHUB_OUTPUT

  # Build job - fast and parallel
  build:
    name: Build Binaries
    runs-on: ubuntu-latest
    needs: setup
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      
    - name: Setup Go Environment
      uses: ./.github/actions/setup-go
      
    - name: Build MCP Server
      run: |
        GOFLAGS=-trimpath go build -o container-kit-mcp ./cmd/mcp-server
        ./container-kit-mcp --version
        
    - name: Build Legacy CLI
      if: needs.setup.outputs.test-cli == 'true'
      run: |
        GOFLAGS=-trimpath go build -o container-kit ./main.go
        ./container-kit --version
        
    - name: Upload CLI Binary
      if: needs.setup.outputs.test-cli == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: container-kit-${{ runner.os }}-${{ github.run_id }}
        path: ./container-kit
        retention-days: 1

  # Quality checks - parallel with build
  quality:
    name: Quality Analysis
    runs-on: ubuntu-latest
    needs: setup
    outputs:
      format-status: ${{ steps.quality-checks.outputs.format-status }}
      lint-status: ${{ steps.quality-checks.outputs.lint-status }}
      static-analysis-status: ${{ steps.quality-checks.outputs.static-analysis-status }}
      security-status: ${{ steps.quality-checks.outputs.security-status }}
      architecture-score: ${{ steps.quality-checks.outputs.architecture-score }}
      architecture-status: ${{ steps.quality-checks.outputs.architecture-status }}
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      
    - name: Setup Go Environment
      uses: ./.github/actions/setup-go
          
    - name: Cache Quality Tools
      uses: actions/cache@v4
      with:
        path: ~/go/bin
        key: ${{ needs.setup.outputs.tools-cache-key }}
        restore-keys: |
          ${{ runner.os }}-quality-tools-
        
    - name: Quality Checks
      id: quality-checks
      uses: ./.github/actions/quality-checks
      with:
        go-version: '1.24.4'
        target-paths: './pkg/mcp/... ./pkg/core/...'
        
    - name: Upload Quality Metrics
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: quality-metrics-${{ github.run_id }}
        path: |
          quality-metrics.json
          metrics-output/
        retention-days: 30

  # Unit tests - depends on build completion
  test:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: [setup, build]
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      
    - name: Setup Go Environment
      uses: ./.github/actions/setup-go
        
    - name: Unit Tests with Race Detection
      run: |
        echo "üèÉ Running unit tests with race detection..."
        go test -race -coverprofile=coverage.out ./pkg/mcp/... ./pkg/core/...
        
        # Check for race conditions in test output
        if grep -q "WARNING: DATA RACE" coverage.out 2>/dev/null; then
          echo "‚ùå Data races detected in tests!"
          exit 1
        else
          echo "‚úÖ No data races detected"
        fi
      
    - name: Test Coverage Analysis
      run: |
        echo "üìä Analyzing test coverage..."
        
        # Generate coverage report
        go tool cover -func=coverage.out > coverage-report.txt
        go tool cover -html=coverage.out -o coverage.html
        
        # Extract overall coverage percentage
        OVERALL_COVERAGE=$(go tool cover -func=coverage.out | grep total | awk '{print $3}' | sed 's/%//')
        echo "Overall coverage: ${OVERALL_COVERAGE}%"
        
        # Load coverage thresholds from config
        OVERALL_TARGET=70
        OVERALL_MINIMUM=50
        if [ -f ".github/quality-config.json" ]; then
          OVERALL_TARGET=$(jq -r '.test_coverage.overall_target // 70' .github/quality-config.json)
          OVERALL_MINIMUM=$(jq -r '.test_coverage.overall_minimum // 50' .github/quality-config.json)
        fi
        
        echo "Coverage targets: minimum=${OVERALL_MINIMUM}%, target=${OVERALL_TARGET}%"
        
        # Check against minimum threshold
        if (( $(echo "$OVERALL_COVERAGE < $OVERALL_MINIMUM" | bc -l 2>/dev/null || echo 0) )); then
          echo "‚ùå Coverage ${OVERALL_COVERAGE}% below minimum threshold ${OVERALL_MINIMUM}%"
          exit 1
        elif (( $(echo "$OVERALL_COVERAGE < $OVERALL_TARGET" | bc -l 2>/dev/null || echo 0) )); then
          echo "‚ö†Ô∏è Coverage ${OVERALL_COVERAGE}% below target ${OVERALL_TARGET}% but above minimum"
        else
          echo "‚úÖ Coverage ${OVERALL_COVERAGE}% meets target ${OVERALL_TARGET}%"
        fi
        
        # Store coverage for status reporting
        echo "COVERAGE_PERCENTAGE=${OVERALL_COVERAGE}" >> $GITHUB_ENV
        
    - name: Upload Coverage Report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: coverage-report-${{ github.run_id }}
        path: |
          coverage.out
          coverage.html
        retention-days: 30

  # MCP Integration tests - lightweight and fast
  mcp-integration:
    name: MCP Integration Tests
    runs-on: ubuntu-latest
    needs: [build, quality, setup]
    if: needs.setup.outputs.test-mcp == 'true' && needs.quality.outputs.architecture-score >= 60
    steps:
    - name: Debug Integration Test Conditions
      run: |
        echo "üîç MCP Integration Test Debug:"
        echo "  test-mcp: '${{ needs.setup.outputs.test-mcp }}'"
        echo "  architecture-score: '${{ needs.quality.outputs.architecture-score }}'"
        echo "  Condition evaluation: ${{ needs.setup.outputs.test-mcp == 'true' && needs.quality.outputs.architecture-score >= '60' }}"
        
    - name: Checkout
      uses: actions/checkout@v4
      
    - name: Setup Docker
      uses: docker/setup-buildx-action@v3
      
    - name: Setup Kind
      uses: helm/kind-action@v1
      with:
        install_only: true
        
    - name: MCP Integration Tests
      run: |
        chmod +x ./test/integration/run_tests.sh
        ./test/integration/run_tests.sh

  # CLI Integration tests - optimized matrix
  cli-integration:
    name: CLI Integration Tests
    runs-on: ubuntu-latest
    needs: [build, quality, setup]
    if: needs.setup.outputs.test-cli == 'true' && needs.quality.outputs.architecture-score >= 60
    strategy:
      max-parallel: 15
      matrix:
        test-repo:
          - Azure-Samples/containerize-and-deploy-Java-app-to-Azure
          - konveyor-ecosystem/coolstore
          - aws-samples/aws-codedeploy-sample-tomcat
        test-number: [1, 2, 3]
      fail-fast: false

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Download CLI binary
      uses: actions/download-artifact@v4
      with:
        name: container-kit-${{ runner.os }}-${{ github.run_id }}
        path: ./

    - name: Run Integration Test
      id: integration-test
      uses: ./.github/actions/integration-test-runner
      with:
        repository: ${{ matrix.test-repo }}
        test-number: ${{ matrix.test-number }}
        binary-name: container-kit
        azure-openai-key: ${{ secrets.AZURE_OPENAI_KEY }}
        azure-openai-endpoint: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
        azure-openai-deployment-id: ${{ secrets.AZURE_OPENAI_DEPLOYMENT_ID }}

    - name: Upload test artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: cc-run-${{ steps.integration-test.outputs.run-name }}
        path: test-repo/artifacts/
        retention-days: 7

  # Aggregate CLI integration results
  aggregate-cli-results:
    name: CLI Integration Summary
    needs: [cli-integration, setup]
    runs-on: ubuntu-latest
    if: always() && needs.setup.outputs.test-cli == 'true' && needs.cli-integration.result != 'skipped'
    outputs:
      success-rate: ${{ steps.aggregate.outputs.success-rate }}
      total-tests: ${{ steps.aggregate.outputs.total-tests }}
      passed-tests: ${{ steps.aggregate.outputs.passed-tests }}
      
    steps:
    - name: Download all results
      uses: actions/download-artifact@v4
      with:
        pattern: cc-run-*
        path: results

    - name: Aggregate Results
      id: aggregate
      run: |
        tests_per_repo=3
        total_tests=0
        passed_tests=0
        
        if [ -d "results" ]; then
          export REPOS="$(ls results | grep -oP 'cc-run-\K[^#]+' | uniq)"
          echo "Processing repos: $REPOS"
          
          for repo in $REPOS; do
            for ((i=1; i<=tests_per_repo; i++)); do
              if [ -f "results/cc-run-$repo#$i/result.txt" ]; then
                result=$(cat "results/cc-run-$repo#$i/result.txt")
                total_tests=$((total_tests + 1))
                if [ "$result" == "success" ]; then
                  passed_tests=$((passed_tests + 1))
                fi
              fi
            done
          done
        fi
        
        success_rate=0
        if [ $total_tests -gt 0 ]; then
          success_rate=$((passed_tests * 100 / total_tests))
        fi
        
        echo "success-rate=$success_rate" >> $GITHUB_OUTPUT
        echo "total-tests=$total_tests" >> $GITHUB_OUTPUT
        echo "passed-tests=$passed_tests" >> $GITHUB_OUTPUT
        
        echo "üìä Integration Test Results: $passed_tests/$total_tests passed ($success_rate%)"

  # Post PR comment with beautiful summary
  pr-comment:
    name: Post PR Summary
    runs-on: ubuntu-latest
    needs: [build, quality, test, mcp-integration, aggregate-cli-results]
    if: always() && github.event_name == 'pull_request'
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      
    - name: Create PR Comment
      uses: ./.github/actions/pr-comment
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        build-status: ${{ needs.build.result }}
        quality-status: ${{ needs.quality.result }}
        test-status: ${{ needs.test.result }}
        mcp-integration-status: ${{ needs.mcp-integration.result }}
        cli-integration-status: ${{ needs.aggregate-cli-results.result }}
        architecture-score: ${{ needs.quality.outputs.architecture-score || '0' }}
        architecture-status: ${{ needs.quality.outputs.architecture-status || 'unknown' }}
        format-status: ${{ needs.quality.outputs.format-status || 'unknown' }}
        lint-status: ${{ needs.quality.outputs.lint-status || 'unknown' }}
        static-analysis-status: ${{ needs.quality.outputs.static-analysis-status || 'unknown' }}
        security-status: ${{ needs.quality.outputs.security-status || 'unknown' }}
        cli-success-rate: ${{ needs.aggregate-cli-results.outputs.success-rate || '0' }}
        cli-total-tests: ${{ needs.aggregate-cli-results.outputs.total-tests || '0' }}
        cli-passed-tests: ${{ needs.aggregate-cli-results.outputs.passed-tests || '0' }}
        ratchet-opportunity: ${{ needs.quality.outputs.ratchet-opportunity || 'false' }}
        current-issues: ${{ needs.quality.outputs.current-issues || '0' }}
        suggested-budget: ${{ needs.quality.outputs.suggested-budget || '0' }}

  # Final status check for branch protection
  ci-status:
    name: CI Status Check
    runs-on: ubuntu-latest
    needs: [build, quality, test, mcp-integration, aggregate-cli-results]
    if: always()
    
    steps:
    - name: Check CI Status
      run: |
        echo "üîç Checking overall CI status..."
        echo "Build: ${{ needs.build.result }}"
        echo "Quality: ${{ needs.quality.result }}"
        echo "Tests: ${{ needs.test.result }}"
        echo "MCP Integration: ${{ needs.mcp-integration.result }}"
        echo "CLI Integration: ${{ needs.aggregate-cli-results.result }}"
        
        # Required checks
        if [[ "${{ needs.build.result }}" != "success" ]]; then
          echo "‚ùå Build failed"
          exit 1
        fi
        
        if [[ "${{ needs.quality.result }}" != "success" ]]; then
          echo "‚ùå Quality checks failed"
          exit 1
        fi
        
        if [[ "${{ needs.test.result }}" != "success" ]]; then
          echo "‚ùå Unit tests failed"
          exit 1
        fi
        
        # MCP integration is required (if it ran)
        if [[ "${{ needs.setup.outputs.test-mcp }}" == "true" ]] && [[ "${{ needs.mcp-integration.result }}" == "failure" ]]; then
          echo "‚ùå MCP integration tests failed"
          exit 1
        elif [[ "${{ needs.setup.outputs.test-mcp }}" != "true" ]]; then
          echo "‚è≠Ô∏è MCP integration tests skipped (no MCP changes detected)"
        fi
        
        # CLI integration is optional (only runs on CLI changes)
        if [[ "${{ needs.setup.outputs.test-cli }}" == "true" ]] && [[ "${{ needs.aggregate-cli-results.result }}" == "failure" ]]; then
          echo "‚ùå CLI integration tests failed"
          exit 1
        elif [[ "${{ needs.setup.outputs.test-cli }}" != "true" ]]; then
          echo "‚è≠Ô∏è CLI integration tests skipped (no CLI changes detected)"
        fi
        
        echo "‚úÖ All CI checks passed!"