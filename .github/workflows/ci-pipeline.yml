name: CI Pipeline

on:
  pull_request:
    branches: [ main ]
  push:
    branches: [ main ]
  workflow_dispatch:

# Cancel in-progress runs when a new commit is pushed
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  issues: write
  pull-requests: write
  statuses: write

jobs:
  # Phase 1: Canary Validation - Fast checks that gate everything else
  canary:
    name: Canary Validation
    runs-on: ubuntu-latest
    outputs:
      should-continue: ${{ steps.canary-check.outputs.success }}
      test-mcp: ${{ steps.detect-paths.outputs.test_mcp }}
      test-core: ${{ steps.detect-paths.outputs.test_core }}
      test-cli: ${{ steps.detect-paths.outputs.test_cli }}

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - uses: actions/setup-go@v5
      with:
        go-version: '1.24'

    - name: Install golangci-lint
      run: |
        curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b $(go env GOPATH)/bin v2.1.6

    - name: Detect changed paths
      id: detect-paths
      run: |
        if [ "${{ github.event_name }}" = "pull_request" ]; then
          # Get changed files
          changed_files=$(git diff --name-only ${{ github.event.pull_request.base.sha }}..HEAD)
          echo "Changed files:"
          echo "$changed_files"

          # Check for MCP changes
          mcp_changes=$(echo "$changed_files" | grep -E "^(pkg/mcp|cmd/mcp-server)" || true)

          # Check for Core changes
          core_changes=$(echo "$changed_files" | grep -E "^(pkg/core|pkg/utils)" || true)

          # Check for CLI changes
          cli_changes=$(echo "$changed_files" | grep -E "^(pkg/ai|pkg/pipeline|cmd/)" || true)

          # Set outputs
          echo "test_mcp=$([ -n "$mcp_changes" ] && echo "true" || echo "false")" >> $GITHUB_OUTPUT
          echo "test_core=$([ -n "$core_changes" ] && echo "true" || echo "false")" >> $GITHUB_OUTPUT
          echo "test_cli=$([ -n "$cli_changes" ] && echo "true" || echo "false")" >> $GITHUB_OUTPUT

          echo "MCP changes: $([ -n "$mcp_changes" ] && echo "yes" || echo "no")"
          echo "Core changes: $([ -n "$core_changes" ] && echo "yes" || echo "no")"
          echo "CLI changes: $([ -n "$cli_changes" ] && echo "yes" || echo "no")"
        else
          # For non-PR events, test everything
          echo "test_mcp=true" >> $GITHUB_OUTPUT
          echo "test_core=true" >> $GITHUB_OUTPUT
          echo "test_cli=true" >> $GITHUB_OUTPUT
          echo "Non-PR event: testing all packages"
        fi

    - name: Canary validation
      id: canary-check
      run: |
        echo "üöÄ Running canary validation..."

        # Test 1: Go mod tidy check
        echo "üìù Testing go mod tidy..."
        cp go.mod go.mod.bak
        cp go.sum go.sum.bak
        go mod tidy
        if ! diff -q go.mod go.mod.bak >/dev/null || ! diff -q go.sum go.sum.bak >/dev/null; then
          echo "‚ùå go mod tidy would make changes - dependencies are not tidy"
          echo "Run 'go mod tidy' locally and commit the changes"
          echo "success=false" >> $GITHUB_OUTPUT
          exit 1
        fi
        echo "‚úÖ Go mod tidy passed"

        # Test 2: Format check
        echo "üé® Testing gofmt..."
        unformatted=$(gofmt -s -l .)
        if [ -n "$unformatted" ]; then
          echo "‚ùå Code formatting issues found:"
          echo "$unformatted"
          echo "Run 'gofmt -s -w .' to fix formatting"
          echo "success=false" >> $GITHUB_OUTPUT
          exit 1
        fi
        echo "‚úÖ Code formatting passed"

        # Test 3: Import formatting check
        echo "üìã Testing goimports..."
        go install golang.org/x/tools/cmd/goimports@latest
        goimports_output=$(goimports -l .)
        if [ -n "$goimports_output" ]; then
          echo "‚ùå Import formatting issues found:"
          echo "$goimports_output"
          echo "Run 'goimports -w .' to fix import formatting"
          echo "success=false" >> $GITHUB_OUTPUT
          exit 1
        fi
        echo "‚úÖ Import formatting passed"

        # Test 4: Build check
        echo "üì¶ Testing build..."
        if ! go build ./...; then
          echo "‚ùå Build failed"
          echo "success=false" >> $GITHUB_OUTPUT
          exit 1
        fi
        echo "‚úÖ Build passed"

        # Test 5: Basic lint check
        echo "üîç Testing lint..."
        if ! golangci-lint run --timeout=5m ./...; then
          echo "‚ùå Lint failed"
          echo "success=false" >> $GITHUB_OUTPUT
          exit 1
        fi
        echo "‚úÖ Lint passed"

        # Test 6: Verify tests compile (don't run them)
        echo "üß™ Verifying tests compile..."
        if ! go test -run=^$ ./...; then
          echo "‚ùå Test compilation failed"
          echo "success=false" >> $GITHUB_OUTPUT
          exit 1
        fi
        echo "‚úÖ Tests compile successfully"

        echo "üéâ All canary checks passed!"
        echo "success=true" >> $GITHUB_OUTPUT

  # Phase 2: Parallel Unit Tests (only run if canary passes)
  unit-test-core:
    name: Unit Tests - Core Packages
    needs: canary
    if: needs.canary.outputs.should-continue == 'true' && needs.canary.outputs.test-core == 'true'
    uses: ./.github/workflows/reusable-go-build.yml
    with:
      go-version: '1.24'
      packages: './pkg/core/... ./pkg/pipeline/... ./pkg/utils/... ./pkg/docker/... ./pkg/k8s/... ./pkg/kind/...'
      run-tests: true
      run-race-tests: true
      run-lint: false
      coverage: true
      job-suffix: 'core'

  unit-test-mcp:
    name: Unit Tests - MCP Packages
    needs: canary
    if: needs.canary.outputs.should-continue == 'true' && needs.canary.outputs.test-mcp == 'true'
    uses: ./.github/workflows/reusable-go-build.yml
    with:
      go-version: '1.24'
      packages: './pkg/mcp/...'
      run-tests: true
      run-race-tests: true
      run-lint: false
      coverage: true
      job-suffix: 'mcp'

  unit-test-cli:
    name: Unit Tests - CLI Packages
    needs: canary
    if: needs.canary.outputs.should-continue == 'true' && needs.canary.outputs.test-cli == 'true'
    uses: ./.github/workflows/reusable-go-build.yml
    with:
      go-version: '1.24'
      packages: './pkg/ai/...'
      run-tests: true
      run-race-tests: true
      run-lint: false
      coverage: true
      job-suffix: 'cli'

  # Phase 3: Build Binaries (parallel with unit tests)
  build-cli:
    name: Build CLI Binary
    needs: canary
    if: needs.canary.outputs.should-continue == 'true'
    uses: ./.github/workflows/reusable-go-build.yml
    with:
      go-version: '1.24'
      packages: './cmd/...'
      run-tests: false
      build-binary: true
      binary-output: 'container-kit'
      binary-main: './main.go'

  build-mcp:
    name: Build MCP Server
    needs: canary
    if: needs.canary.outputs.should-continue == 'true'
    uses: ./.github/workflows/reusable-go-build.yml
    with:
      go-version: '1.24'
      packages: './cmd/mcp-server/...'
      run-tests: false
      build-binary: true
      binary-output: 'container-kit-mcp'
      binary-main: './cmd/mcp-server'

  # Phase 4: Coverage Enforcement & Ratchet (after unit tests)
  coverage-enforcement:
    name: Coverage Enforcement
    runs-on: ubuntu-latest
    needs: [canary, unit-test-core, unit-test-mcp, unit-test-cli]
    if: always() && needs.canary.outputs.should-continue == 'true' && !failure()

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: '1.24'

    - name: Cache Go modules
      uses: actions/cache@v4
      with:
        path: ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Install dependencies
      run: go mod download

    - name: Download coverage artifacts
      uses: actions/download-artifact@v4
      with:
        pattern: coverage-*-${{ github.run_id }}
        path: coverage-artifacts

    - name: Merge coverage reports
      run: |
        echo "üìä Merging coverage reports from unit tests..."
        
        # Install gocovmerge if not available
        go install github.com/wadey/gocovmerge@latest
        
        # Find all coverage files and merge them
        coverage_files=$(find coverage-artifacts -name "coverage.out" -type f)
        if [ -n "$coverage_files" ]; then
          echo "Found coverage files: $coverage_files"
          ~/go/bin/gocovmerge $coverage_files > merged-coverage.out
          cp merged-coverage.out coverage.out
          echo "‚úÖ Merged coverage reports successfully"
        else
          echo "‚ö†Ô∏è No coverage artifacts found, will generate coverage during enforcement"
        fi

    - name: Run coverage enforcement for core packages
      run: |
        echo "üìä Running coverage enforcement..."

        # Define core packages that need coverage enforcement
        CORE_PACKAGES=(
          "./pkg/mcp/internal/core/..."
          "./pkg/mcp/internal/runtime/..."
          "./pkg/mcp/internal/orchestration/..."
          "./pkg/mcp/internal/session/..."
          "./pkg/mcp/internal/build/..."
          "./pkg/mcp/internal/deploy/..."
          "./pkg/mcp/internal/analyze/..."
          "./pkg/mcp/internal/server/..."
          "./pkg/mcp/types/..."
        )

        # Coverage thresholds (minimum required coverage percentages)
        # Load from configuration file if available, otherwise use defaults
        declare -A COVERAGE_THRESHOLDS
        
        if [ -f .github/coverage-thresholds.json ]; then
          echo "Loading coverage thresholds from configuration file..."
          # Parse JSON and populate the array
          while IFS="=" read -r package threshold; do
            COVERAGE_THRESHOLDS["$package"]="$threshold"
          done < <(jq -r '.package_thresholds | to_entries[] | select(.key | endswith("...")) | "\(.key)=\(.value.threshold)"' .github/coverage-thresholds.json)
        else
          echo "Using default coverage thresholds..."
          COVERAGE_THRESHOLDS["./pkg/mcp/internal/core/..."]=30
          COVERAGE_THRESHOLDS["./pkg/mcp/internal/runtime/..."]=20
          COVERAGE_THRESHOLDS["./pkg/mcp/internal/orchestration/..."]=1
          COVERAGE_THRESHOLDS["./pkg/mcp/internal/session/..."]=9
          COVERAGE_THRESHOLDS["./pkg/mcp/internal/build/..."]=6
          COVERAGE_THRESHOLDS["./pkg/mcp/internal/deploy/..."]=7
          COVERAGE_THRESHOLDS["./pkg/mcp/internal/analyze/..."]=14
          COVERAGE_THRESHOLDS["./pkg/mcp/internal/server/..."]=17
          COVERAGE_THRESHOLDS["./pkg/mcp/types/..."]=30
        fi

        FAILED_PACKAGES=()

        # Check if we have a merged coverage file
        if [ -f "coverage.out" ]; then
          echo "Using merged coverage file from unit tests"
          USE_MERGED_COVERAGE=true
        else
          echo "No merged coverage file found, will run tests for each package"
          USE_MERGED_COVERAGE=false
        fi

        for package in "${CORE_PACKAGES[@]}"; do
          echo "Checking coverage for $package..."

          if [ "$USE_MERGED_COVERAGE" = "true" ]; then
            # Extract coverage from merged file
            coverage_line=$(go tool cover -func=coverage.out | grep -E "^${package//\./\\.}" | grep -v "test" | awk '{sum+=$3; count++} END {if(count>0) printf "%.1f\n", sum/count; else print "0.0"}')
            if [ -n "$coverage_line" ] && [ "$coverage_line" != "0.0" ]; then
              coverage_percent="$coverage_line"
            else
              # Package might not be in merged coverage, run test for this package only
              coverage_file="/tmp/coverage-$(echo $package | tr '/' '-' | tr '.' '-').out"
              if go test -coverprofile="$coverage_file" "$package" 2>/dev/null; then
                coverage_line=$(go tool cover -func="$coverage_file" | grep "total:" | tail -1)
                coverage_percent=$(echo "$coverage_line" | awk '{print $3}' | sed 's/%//')
              else
                coverage_percent="0.0"
              fi
            fi
          else
            # Run tests with coverage for this package
            coverage_file="/tmp/coverage-$(echo $package | tr '/' '-' | tr '.' '-').out"
            if go test -coverprofile="$coverage_file" "$package" 2>/dev/null; then
              if [ -f "$coverage_file" ]; then
                # Extract coverage percentage
                coverage_line=$(go tool cover -func="$coverage_file" | grep "total:" | tail -1)
                if [ -n "$coverage_line" ]; then
                  coverage_percent=$(echo "$coverage_line" | awk '{print $3}' | sed 's/%//')
                else
                  coverage_percent="0.0"
                fi
              else
                coverage_percent="0.0"
              fi
            else
              coverage_percent="0.0"
            fi
          fi

          threshold=${COVERAGE_THRESHOLDS[$package]}

                echo "Package $package: ${coverage_percent}% coverage (threshold: ${threshold}%)"

                # Compare coverage with threshold
                if (( $(echo "$coverage_percent < $threshold" | bc -l) )); then
                  echo "‚ùå $package coverage ${coverage_percent}% is below threshold ${threshold}%"
                  FAILED_PACKAGES+=("$package (${coverage_percent}% < ${threshold}%)")
                else
                  echo "‚úÖ $package coverage ${coverage_percent}% meets threshold ${threshold}%"
                fi
              else
                echo "‚ö†Ô∏è Could not extract coverage for $package"
              fi
            else
              echo "‚ö†Ô∏è No coverage file generated for $package"
            fi
          else
            echo "‚ö†Ô∏è Tests failed for $package"
          fi
        done

        # Report results
        if [ ${#FAILED_PACKAGES[@]} -eq 0 ]; then
          echo "üéâ All packages meet coverage requirements!"
        else
          echo "‚ùå Coverage enforcement failed for the following packages:"
          for pkg in "${FAILED_PACKAGES[@]}"; do
            echo "  - $pkg"
          done
          echo ""
          echo "Please add tests to increase coverage for the failing packages."
          exit 1
        fi

    - name: Download coverage artifacts from unit tests
      uses: actions/download-artifact@v4
      with:
        pattern: coverage-*
        path: coverage-artifacts

    - name: Generate global coverage report
      run: |
        echo "üìä Generating global coverage report..."

        # Merge coverage files from unit tests
        echo "mode: atomic" > coverage.out

        # Find all coverage files and merge them
        for file in coverage-artifacts/*/coverage.out; do
          if [ -f "$file" ]; then
            echo "Merging coverage from: $file"
            # Skip the first line (mode: atomic) and append the rest
            tail -n +2 "$file" >> coverage.out
          fi
        done

        # Check if we have any coverage data
        if [ $(wc -l < coverage.out) -le 1 ]; then
          echo "‚ö†Ô∏è No coverage data found from unit tests. Running tests now..."
          go test -v -coverprofile=coverage.out -covermode=atomic ./...
        fi

        # Generate HTML report
        go tool cover -html=coverage.out -o coverage.html

        # Install coverage tools
        go install github.com/axw/gocov/gocov@latest
        go install github.com/AlekSi/gocov-xml@latest

        # Convert coverage to XML
        gocov convert coverage.out | gocov-xml > coverage.xml

        # Generate coverage summary
        go tool cover -func=coverage.out > coverage-summary.txt
        echo "## Global Coverage Summary" >> $GITHUB_STEP_SUMMARY
        echo '```' >> $GITHUB_STEP_SUMMARY
        cat coverage-summary.txt >> $GITHUB_STEP_SUMMARY
        echo '```' >> $GITHUB_STEP_SUMMARY

    - name: Check global coverage thresholds
      run: |
        # Extract total coverage
        TOTAL_COV=$(go tool cover -func=coverage.out | grep total | awk '{print $3}' | sed 's/%//')
        echo "Total coverage: ${TOTAL_COV}%"

        # Set default thresholds (can be overridden with config file)
        MIN_THRESHOLD=10    # Minimum acceptable coverage
        TARGET_THRESHOLD=25 # Target coverage goal

        # Try to load from config file if it exists
        if [ -f .github/coverage-thresholds.json ]; then
          MIN_THRESHOLD=$(jq -r '.global.line_coverage.minimum' .github/coverage-thresholds.json 2>/dev/null || echo "10")
          TARGET_THRESHOLD=$(jq -r '.global.line_coverage.target' .github/coverage-thresholds.json 2>/dev/null || echo "25")
        fi

        echo "Minimum threshold: ${MIN_THRESHOLD}%"
        echo "Target threshold: ${TARGET_THRESHOLD}%"

        # Check if coverage meets minimum
        if (( $(echo "$TOTAL_COV < $MIN_THRESHOLD" | bc -l) )); then
          echo "‚ùå Global coverage ${TOTAL_COV}% is below minimum threshold ${MIN_THRESHOLD}%"
          exit 1
        fi

        # Check if coverage meets target
        if (( $(echo "$TOTAL_COV >= $TARGET_THRESHOLD" | bc -l) )); then
          echo "‚úÖ Global coverage ${TOTAL_COV}% meets target threshold ${TARGET_THRESHOLD}%"
        else
          echo "‚ö†Ô∏è Global coverage ${TOTAL_COV}% meets minimum but is below target ${TARGET_THRESHOLD}%"
        fi

    - name: Check coverage ratchet (PR only)
      if: github.event_name == 'pull_request'
      run: |
        echo "üîÑ Checking coverage ratchet..."

        # Get base branch coverage
        git checkout ${{ github.event.pull_request.base.sha }}
        go test -coverprofile=base-coverage.out ./... > /dev/null 2>&1 || true

        if [ -f base-coverage.out ]; then
          BASE_COV=$(go tool cover -func=base-coverage.out | grep total | awk '{print $3}' | sed 's/%//')
          git checkout ${{ github.event.pull_request.head.sha }}
          CURRENT_COV=$(go tool cover -func=coverage.out | grep total | awk '{print $3}' | sed 's/%//')

          echo "Base coverage: ${BASE_COV}%"
          echo "Current coverage: ${CURRENT_COV}%"

          # Calculate difference
          DIFF=$(echo "$CURRENT_COV - $BASE_COV" | bc -l)

          # Set default tolerance (can be overridden with config file)
          # Note: Temporarily increased to 3.5% to account for dead code cleanup impact
          TOLERANCE=3.5
          if [ -f .github/coverage-thresholds.json ]; then
            TOLERANCE=$(jq -r '.ratchet.regression_tolerance' .github/coverage-thresholds.json 2>/dev/null || echo "3.5")
          fi

          echo "Coverage change: ${DIFF}% (tolerance: -${TOLERANCE}%)"

          if (( $(echo "$DIFF < -$TOLERANCE" | bc -l) )); then
            echo "‚ùå Coverage regression detected: ${DIFF}% (tolerance: -${TOLERANCE}%)"
            echo "## Coverage Ratchet Failed ‚ùå" >> $GITHUB_STEP_SUMMARY
            echo "Coverage decreased by ${DIFF}% which exceeds tolerance of -${TOLERANCE}%" >> $GITHUB_STEP_SUMMARY
            exit 1
          else
            echo "‚úÖ Coverage ratchet passed: ${DIFF}%"
            echo "## Coverage Ratchet Passed ‚úÖ" >> $GITHUB_STEP_SUMMARY
            echo "Coverage change: ${DIFF}%" >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "‚ö†Ô∏è Could not determine base coverage, skipping ratchet check"
          echo "## Coverage Ratchet Skipped ‚ö†Ô∏è" >> $GITHUB_STEP_SUMMARY
          echo "Base coverage could not be determined" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Upload coverage reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: global-coverage-reports-${{ github.run_id }}
        path: |
          coverage.out
          coverage.html
          coverage.xml
          coverage-summary.txt
          base-coverage.out
        retention-days: 30

  # Phase 5: Security Scanning (parallel with coverage)
  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    needs: [canary, unit-test-core, unit-test-mcp, unit-test-cli]
    if: always() && needs.canary.outputs.should-continue == 'true' && !failure()

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup Go
      uses: actions/setup-go@v5
      with:
        go-version: '1.24'

    - name: Install Security Scanners
      run: |
        echo "üîí Installing security scanners..."
        sudo apt-get update
        sudo apt-get install -y wget apt-transport-https gnupg lsb-release bc

        # Install Trivy
        wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -
        echo "deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main" | sudo tee -a /etc/apt/sources.list.d/trivy.list
        sudo apt-get update
        sudo apt-get install -y trivy

        # Install GitLeaks
        wget https://github.com/zricethezav/gitleaks/releases/download/v8.18.0/gitleaks_8.18.0_linux_x64.tar.gz
        tar xzf gitleaks_8.18.0_linux_x64.tar.gz
        sudo mv gitleaks /usr/local/bin/
        chmod +x /usr/local/bin/gitleaks

    - name: Run GitLeaks (Secret Detection)
      run: |
        echo "üîç Scanning for secrets..."

        # Create gitleaks config to exclude test files and known test patterns
        cat > .gitleaks.toml << 'EOF'
        [allowlist]
          description = "Test secrets and known safe patterns"

          # Exclude test files
          files = [
            '''.*_test\.go''',
            '''.*test.*\.go''',
            '''test/.*''',
            '''.*testdata.*''',
            '''examples/.*''',
            '''repomix-output\.xml'''
          ]

          # Exclude known test patterns
          regexes = [
            '''sk-1234567890abcdef''',
            '''AKIAFAKETEST12345678''',
            '''AKIAIOSFODNN7EXAMPLE''',
            '''test-api-key-123456''',
            '''zN8BP6lnPUDpumenHCZLVwZkFcSIGPr0''',
            '''dGhpcyBpcyBhIHNlY3JldCBtZXNzYWdl''',
            '''4e1243bd22c66e76c2ba9bef8c5e8f8a''',
            '''YOUR_PRIVATE_KEY_CONTENT_HERE_REPLACE_WITH_ACTUAL_KEY''',
            '''eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9\.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE''',
            '''dXNlcjpwYXNzd29yZA==''',
            '''abc123def456''',
            '''sk_test_abcdef123456'''
          ]
        EOF

        # Run gitleaks with config
        gitleaks detect --config .gitleaks.toml --report-format json --report-path gitleaks-report.json --verbose

        if [ -f gitleaks-report.json ]; then
          leak_count=$(jq '. | length' gitleaks-report.json 2>/dev/null || echo "0")
          echo "Found $leak_count potential secrets"

          if [ "$leak_count" -gt 0 ]; then
            echo "‚ùå Potential secrets found!"
            jq -r '.[] | "- \(.RuleID): \(.File):\(.StartLine) - \(.Description)"' gitleaks-report.json
            exit 1
          else
            echo "‚úÖ No secrets detected"
          fi
        else
          echo "‚úÖ No secrets detected"
        fi

    - name: Run Trivy (Vulnerability Scanning)
      run: |
        echo "üõ°Ô∏è Scanning for vulnerabilities..."

        # Scan filesystem for vulnerabilities
        trivy fs --format json --output trivy-fs-report.json .

        # Scan for configuration issues
        trivy config --format json --output trivy-config-report.json .

        # Process results
        fs_vulns=$(jq '.Results[]?.Vulnerabilities? // [] | length' trivy-fs-report.json | awk '{sum += $1} END {print sum+0}')
        config_issues=$(jq '.Results[]?.Misconfigurations? // [] | length' trivy-config-report.json | awk '{sum += $1} END {print sum+0}')

        echo "Found $fs_vulns filesystem vulnerabilities"
        echo "Found $config_issues configuration issues"

        # Report critical/high severity issues
        critical_vulns=$(jq '.Results[]?.Vulnerabilities? // [] | map(select(.Severity == "CRITICAL" or .Severity == "HIGH")) | length' trivy-fs-report.json | awk '{sum += $1} END {print sum+0}')

        if [ "$critical_vulns" -gt 0 ]; then
          echo "‚ùå Found $critical_vulns critical/high severity vulnerabilities!"
          jq -r '.Results[]?.Vulnerabilities? // [] | map(select(.Severity == "CRITICAL" or .Severity == "HIGH")) | .[] | "- \(.Severity): \(.VulnerabilityID) in \(.PkgName) - \(.Title)"' trivy-fs-report.json
          exit 1
        else
          echo "‚úÖ No critical or high severity vulnerabilities found"
        fi

    - name: Upload security reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports-${{ github.run_id }}
        path: |
          gitleaks-report.json
          trivy-fs-report.json
          trivy-config-report.json
        retention-days: 30

  # Phase 6: Quality Gates (after coverage and security)
  quality-gates:
    name: Quality Gate Checks
    runs-on: ubuntu-latest
    needs: [canary, unit-test-core, unit-test-mcp, unit-test-cli, coverage-enforcement, security-scan]
    if: always() && needs.canary.outputs.should-continue == 'true' && !failure()

    steps:
    - name: Quality gates summary
      run: |
        echo "üéØ Quality Gates Summary"
        echo "‚úÖ All unit tests passed"
        echo "‚úÖ All builds completed successfully"
        echo "‚úÖ Coverage enforcement passed"
        echo "‚úÖ Security scanning passed"
        echo "üéâ All quality gates passed!"

  # Phase 5: Integration Tests (after everything else)
  integration-tests:
    name: Integration Tests
    needs: [canary, unit-test-core, unit-test-cli, build-cli]
    if: always() && needs.canary.outputs.should-continue == 'true' && !failure() && needs.canary.outputs.test-cli == 'true'
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Download CLI binary
      uses: actions/download-artifact@v4
      with:
        name: container-kit-ubuntu-latest-${{ github.run_id }}
        path: ./

    - name: Run integration tests
      run: |
        chmod +x container-kit
        echo "üß™ Running integration tests..."
        echo "Integration tests would run here with the built binary"

  # Phase 6: MCP Integration Tests (parallel with integration tests)
  mcp-integration-tests:
    name: MCP Integration Tests
    needs: [canary, unit-test-mcp, build-mcp]
    if: always() && needs.canary.outputs.should-continue == 'true' && !failure() && needs.canary.outputs.test-mcp == 'true'
    runs-on: ubuntu-latest

    services:
      docker:
        image: docker:dind
        options: --privileged

    steps:
    - uses: actions/checkout@v4

    - uses: actions/setup-go@v5
      with:
        go-version: '1.24'

    - name: Install Kind
      run: |
        curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
        chmod +x ./kind
        sudo mv ./kind /usr/local/bin/kind

    - name: Cache Go modules
      uses: actions/cache@v4
      with:
        path: ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Download dependencies
      run: go mod download

    - name: Run MCP unit tests
      run: go test -v ./pkg/mcp/... -short

    - name: Run MCP unit tests with race detector
      run: go test -race -v ./pkg/mcp/... -short

    - name: Build MCP server
      run: go build -o container-kit-mcp ./cmd/mcp-server

    - name: Run MCP integration tests
      run: |
        export CONTAINER_KIT_TEST_WORKSPACE="/tmp/container-kit-test"
        export CONTAINER_KIT_LOG_LEVEL="debug"
        mkdir -p "$CONTAINER_KIT_TEST_WORKSPACE"
        go test -v ./test/integration/...

  # Phase 7: Testing Dashboard (after all tests complete)
  testing-dashboard:
    name: Testing Dashboard
    runs-on: ubuntu-latest
    needs: [canary, unit-test-core, unit-test-mcp, unit-test-cli, coverage-enforcement, security-scan, quality-gates]
    if: always() && needs.canary.outputs.should-continue == 'true'

    steps:

    - name: Generate testing dashboard
      timeout-minutes: 2
      run: |
        echo "üìä Generating fast testing dashboard..."

        # Create a simple testing report using data from previous jobs
        cat > /tmp/testing-report.md << 'EOF'
        # üß™ Testing Progress Dashboard

        ## Pipeline Status Summary
        | Component | Status |
        |-----------|--------|
        | Canary Validation | ${{ needs.canary.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |
        | Unit Tests (Core) | ${{ needs.unit-test-core.result == 'success' && '‚úÖ Passed' || needs.unit-test-core.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed' }} |
        | Unit Tests (MCP) | ${{ needs.unit-test-mcp.result == 'success' && '‚úÖ Passed' || needs.unit-test-mcp.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed' }} |
        | Unit Tests (CLI) | ${{ needs.unit-test-cli.result == 'success' && '‚úÖ Passed' || needs.unit-test-cli.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed' }} |
        | Coverage Enforcement | ${{ needs.coverage-enforcement.result == 'success' && '‚úÖ Passed' || needs.coverage-enforcement.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed' }} |
        | Security Scanning | ${{ needs.security-scan.result == 'success' && '‚úÖ Passed' || needs.security-scan.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed' }} |
        | Quality Gates | ${{ needs.quality-gates.result == 'success' && '‚úÖ Passed' || needs.quality-gates.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed' }} |

        ## üìã Quick Stats
        - **Workflow**: CI Pipeline
        - **Run ID**: ${{ github.run_id }}
        - **Commit**: ${{ github.sha }}
        - **Branch**: ${{ github.ref_name }}

        ## üîó Detailed Results
        For detailed test results, coverage reports, and logs, check the [GitHub Actions run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}).

        ## üìä Coverage Reports
        Coverage reports are available in the artifacts of this workflow run.

        ---
        *Generated by GitHub Actions*
        EOF

        echo "‚úÖ Fast testing dashboard generated successfully"

    - name: Upload test coverage reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: testing-dashboard-coverage-${{ github.run_id }}
        path: |
          /tmp/coverage-*.out
          coverage.out
        retention-days: 7

    - name: Upload testing report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: testing-report-${{ github.run_id }}
        path: /tmp/testing-report.md
        retention-days: 30

  # Final Phase: Pipeline Summary
  pipeline-summary:
    name: Pipeline Summary
    runs-on: ubuntu-latest
    needs: [canary, unit-test-core, unit-test-mcp, unit-test-cli, build-cli, build-mcp, coverage-enforcement, security-scan, quality-gates, integration-tests, mcp-integration-tests, testing-dashboard]
    if: always()
    permissions:
      pull-requests: write
      issues: write

    steps:
    - name: Download artifacts
      uses: actions/download-artifact@v4
      with:
        pattern: "*-${{ github.run_id }}"
        path: artifacts
      continue-on-error: true

    - name: Prepare CI Status Data
      id: ci-status
      run: |
        # Extract security scan results
        SECURITY_SECRETS="‚ö†Ô∏è No Data: Security scan report not available"
        SECURITY_VULNERABILITIES="‚ö†Ô∏è No Data: Vulnerability scan report not available"

        if [ -f "artifacts/security-reports-${{ github.run_id }}/gitleaks-report.json" ]; then
          leak_count=$(jq '. | length' artifacts/security-reports-${{ github.run_id }}/gitleaks-report.json 2>/dev/null || echo "0")
          if [ "$leak_count" = "0" ]; then
            SECURITY_SECRETS="‚úÖ Passed: No secrets detected"
          else
            SECURITY_SECRETS="‚ùå Failed: $leak_count secrets detected"
          fi
        fi

        if [ -f "artifacts/security-reports-${{ github.run_id }}/trivy-fs-report.json" ]; then
          vuln_count=$(jq '.Results[].Vulnerabilities | length' artifacts/security-reports-${{ github.run_id }}/trivy-fs-report.json 2>/dev/null | awk '{s+=$1} END {print s}' || echo "0")
          if [ "$vuln_count" = "0" ] || [ -z "$vuln_count" ]; then
            SECURITY_VULNERABILITIES="‚úÖ Passed: No vulnerabilities detected"
          else
            SECURITY_VULNERABILITIES="‚ùå Failed: $vuln_count vulnerabilities detected"
          fi
        fi

        # Extract lint results
        # If we reach this point, linting passed (otherwise workflow would have failed)
        LINT_RESULTS="‚úÖ Passed: All linting checks completed successfully"

        # Extract coverage results
        COVERAGE_RESULTS="‚ö†Ô∏è No Data: Coverage report not available"
        if [ -f "artifacts/global-coverage-reports-${{ github.run_id }}/coverage-summary.txt" ]; then
          total_cov=$(grep "total:" artifacts/global-coverage-reports-${{ github.run_id }}/coverage-summary.txt | awk '{print $3}' || echo "unknown")
          COVERAGE_RESULTS="üìä Total Coverage: $total_cov\n\n"
          COVERAGE_RESULTS+="Package Coverage:\n"
          # Get top packages
          head -n 20 artifacts/global-coverage-reports-${{ github.run_id }}/coverage-summary.txt | grep -E "github.com/Azure/container-kit" | while read line; do
            COVERAGE_RESULTS+="- $line\n"
          done
        fi

        # Extract quality gates results
        QUALITY_RESULTS="‚ö†Ô∏è No Data: Quality metrics not available"
        if [ "${{ needs.quality-gates.result }}" = "success" ]; then
          QUALITY_RESULTS="‚úÖ All quality checks passed"
        elif [ "${{ needs.quality-gates.result }}" = "failure" ]; then
          QUALITY_RESULTS="‚ùå Quality checks failed"
        fi

        # Save to outputs
        echo "security_secrets<<EOF" >> $GITHUB_OUTPUT
        echo "$SECURITY_SECRETS" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT

        echo "security_vulnerabilities<<EOF" >> $GITHUB_OUTPUT
        echo "$SECURITY_VULNERABILITIES" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT

        echo "lint_results<<EOF" >> $GITHUB_OUTPUT
        echo -e "$LINT_RESULTS" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT

        echo "coverage_results<<EOF" >> $GITHUB_OUTPUT
        echo -e "$COVERAGE_RESULTS" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT

        echo "quality_results<<EOF" >> $GITHUB_OUTPUT
        echo "$QUALITY_RESULTS" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT

    - name: Create PR Comment
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const body = `## ü§ñ CI Status Summary

          ### üîí Security Scan
          ${{ steps.ci-status.outputs.security_secrets }}

          ${{ steps.ci-status.outputs.security_vulnerabilities }}

          ### üßπ Lint Results
          ${{ steps.ci-status.outputs.lint_results }}

          [View detailed results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})

          ### üìä Test Coverage
          ${{ steps.ci-status.outputs.coverage_results }}

          ### üéØ Quality Gates
          ${{ steps.ci-status.outputs.quality_results }}

          ### üìù Next Steps:
          - Review any failed checks above
          - Check individual workflow runs for detailed logs
          - Address issues before merging

          ---
          *This comment is automatically updated as CI jobs complete.*`;

          // Find existing comment
          const { data: comments } = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
          });

          const botComment = comments.find(comment =>
            comment.user.type === 'Bot' &&
            comment.body.includes('ü§ñ CI Status Summary')
          );

          if (botComment) {
            // Update existing comment
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: botComment.id,
              body: body
            });
          } else {
            // Create new comment
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: body
            });
          }

    - name: Pipeline Summary
      run: |
        echo "## üöÄ CI Pipeline Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Phase Results" >> $GITHUB_STEP_SUMMARY
        echo "| Phase | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| Canary Validation | ${{ needs.canary.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Core Unit Tests | ${{ needs.unit-test-core.result == 'success' && '‚úÖ Passed' || needs.unit-test-core.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| MCP Unit Tests | ${{ needs.unit-test-mcp.result == 'success' && '‚úÖ Passed' || needs.unit-test-mcp.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| CLI Unit Tests | ${{ needs.unit-test-cli.result == 'success' && '‚úÖ Passed' || needs.unit-test-cli.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| CLI Build | ${{ needs.build-cli.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| MCP Build | ${{ needs.build-mcp.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Coverage Enforcement | ${{ needs.coverage-enforcement.result == 'success' && '‚úÖ Passed' || needs.coverage-enforcement.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Security Scan | ${{ needs.security-scan.result == 'success' && '‚úÖ Passed' || needs.security-scan.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Quality Gates | ${{ needs.quality-gates.result == 'success' && '‚úÖ Passed' || needs.quality-gates.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Integration Tests | ${{ needs.integration-tests.result == 'success' && '‚úÖ Passed' || needs.integration-tests.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| MCP Integration Tests | ${{ needs.mcp-integration-tests.result == 'success' && '‚úÖ Passed' || needs.mcp-integration-tests.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Testing Dashboard | ${{ needs.testing-dashboard.result == 'success' && '‚úÖ Passed' || needs.testing-dashboard.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        # Overall result
        if [ "${{ needs.canary.result }}" = "success" ]; then
          echo "### Overall Result: ‚úÖ Pipeline Completed Successfully" >> $GITHUB_STEP_SUMMARY
        else
          echo "### Overall Result: ‚ùå Pipeline Failed at Canary Stage" >> $GITHUB_STEP_SUMMARY
        fi

  # Status Check - Single job to use as required check in branch protection
  # This job will only pass if ALL required jobs pass
  ci-status-check:
    name: CI Status Check
    runs-on: ubuntu-latest
    needs: [canary, unit-test-core, unit-test-mcp, unit-test-cli, build-cli, build-mcp, coverage-enforcement, security-scan, quality-gates, integration-tests, mcp-integration-tests, testing-dashboard]
    if: always()
    steps:
      - name: Check all required jobs
        run: |
          echo "Checking status of all required jobs..."
          
          # Check each job result
          FAILED_JOBS=""
          
          # Canary must always pass
          if [ "${{ needs.canary.result }}" != "success" ]; then
            FAILED_JOBS="${FAILED_JOBS}canary "
          fi
          
          # Build jobs must pass
          if [ "${{ needs.build-cli.result }}" != "success" ]; then
            FAILED_JOBS="${FAILED_JOBS}build-cli "
          fi
          if [ "${{ needs.build-mcp.result }}" != "success" ]; then
            FAILED_JOBS="${FAILED_JOBS}build-mcp "
          fi
          
          # Unit tests must pass if they ran (not skipped)
          if [ "${{ needs.unit-test-core.result }}" != "success" ] && [ "${{ needs.unit-test-core.result }}" != "skipped" ]; then
            FAILED_JOBS="${FAILED_JOBS}unit-test-core "
          fi
          if [ "${{ needs.unit-test-mcp.result }}" != "success" ] && [ "${{ needs.unit-test-mcp.result }}" != "skipped" ]; then
            FAILED_JOBS="${FAILED_JOBS}unit-test-mcp "
          fi
          if [ "${{ needs.unit-test-cli.result }}" != "success" ] && [ "${{ needs.unit-test-cli.result }}" != "skipped" ]; then
            FAILED_JOBS="${FAILED_JOBS}unit-test-cli "
          fi
          
          # Coverage must pass if it ran
          if [ "${{ needs.coverage-enforcement.result }}" != "success" ] && [ "${{ needs.coverage-enforcement.result }}" != "skipped" ]; then
            FAILED_JOBS="${FAILED_JOBS}coverage-enforcement "
          fi
          
          # Security scan must pass if it ran
          if [ "${{ needs.security-scan.result }}" != "success" ] && [ "${{ needs.security-scan.result }}" != "skipped" ]; then
            FAILED_JOBS="${FAILED_JOBS}security-scan "
          fi
          
          # Quality gates must pass if it ran
          if [ "${{ needs.quality-gates.result }}" != "success" ] && [ "${{ needs.quality-gates.result }}" != "skipped" ]; then
            FAILED_JOBS="${FAILED_JOBS}quality-gates "
          fi
          
          # Integration tests must pass if they ran
          if [ "${{ needs.integration-tests.result }}" != "success" ] && [ "${{ needs.integration-tests.result }}" != "skipped" ]; then
            FAILED_JOBS="${FAILED_JOBS}integration-tests "
          fi
          if [ "${{ needs.mcp-integration-tests.result }}" != "success" ] && [ "${{ needs.mcp-integration-tests.result }}" != "skipped" ]; then
            FAILED_JOBS="${FAILED_JOBS}mcp-integration-tests "
          fi
          
          # Testing dashboard must pass if it ran
          if [ "${{ needs.testing-dashboard.result }}" != "success" ] && [ "${{ needs.testing-dashboard.result }}" != "skipped" ]; then
            FAILED_JOBS="${FAILED_JOBS}testing-dashboard "
          fi
          
          # Fail if any required jobs failed
          if [ -n "$FAILED_JOBS" ]; then
            echo "‚ùå The following required jobs failed: $FAILED_JOBS"
            exit 1
          else
            echo "‚úÖ All required CI checks passed!"
          fi
