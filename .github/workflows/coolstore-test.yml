name: Coolstore Integration Test

on:
  workflow_dispatch:
  pull_request:

jobs:
  test-coolstore:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout container-copilot
        uses: actions/checkout@v3

      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: '1.23'
      
      - name: Build container-copilot
        run: |
          go build -o container-copilot .
          sudo mv container-copilot /usr/local/bin/ #install onto system path

      - name: Checkout Konveyor Coolstore
        uses: actions/checkout@v3
        with:
          repository: konveyor-ecosystem/coolstore
          path: coolstore

      - name: Setup Docker
        uses: docker/setup-buildx-action@v3

      - name: Install Kind
        uses: helm/kind-action@v1
        with:
          install_only: true

      - name: Run Parallel Tests
        id: container_copilot_runs
        env:
          AZURE_OPENAI_KEY: ${{ secrets.AZURE_OPENAI_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
          AZURE_OPENAI_DEPLOYMENT_ID: ${{ secrets.AZURE_OPENAI_DEPLOYMENT_ID }}
        run: |
          cd coolstore
          
          # Track our results
          success_count=0
          failure_count=0
          
          # Make sure we have a place to store logs and artifacts
          mkdir -p logs
          mkdir -p artifacts
          
          # The success message we're looking for in the output
          SUCCESS_MESSAGE="Container deployment pipeline completed successfully!"
          
          # Run tests in parallel using background processes
          for i in {1..5}; do
            # Create a function for each test
            test_func() {
              local i=$1
              echo "===== Starting Test Run $i of 5 ====="
              
              # Create a separate directory for each test run
              mkdir -p test-run-${i}
              cd test-run-${i}
              
              # Copy the source code to this directory
              cp -r ../* ./ 2>/dev/null || true
              
              # Start with a clean slate
              rm -f Dockerfile || true
              rm -rf manifests || true
              mkdir -p manifests
              
              # Run the test and save output
              echo "Running container-copilot generate for test $i..."
              container-copilot generate . > "../logs/run-${i}.log" 2>&1
              
              # Check if the success message is in the log file
              if grep -q "$SUCCESS_MESSAGE" "../logs/run-${i}.log"; then
                echo "✅ Test Run $i: PASSED - Found '$SUCCESS_MESSAGE'"
                
                # Save the files it created
                mkdir -p ../artifacts/run-${i}
                [ -f Dockerfile ] && cp Dockerfile ../artifacts/run-${i}/ || echo "No Dockerfile created"
                [ -d manifests ] && [ "$(ls -A manifests)" ] && cp -r manifests/* ../artifacts/run-${i}/ || echo "No manifests created"
                
                # Signal success by creating empty file 
                touch ../test-${i}-success
              else
                echo "❌ Test Run $i: FAILED - Did not find '$SUCCESS_MESSAGE'"
                # Signal failure
                touch ../test-${i}-failure
              fi
              
              # Always save the logs
              mkdir -p ../artifacts/run-${i}
              # Log already saved to logs directory
              
              # Return to parent directory
              cd ..
            }
            
            # Run the test function in the background
            test_func $i &
          done
          
          # Wait for all background processes to complete
          wait
          
          # Count successes and failures
          success_count=$(ls test-*-success 2>/dev/null | wc -l)
          failure_count=$(ls test-*-failure 2>/dev/null | wc -l)
          
          # Build detailed results
          passed_tests=""
          failed_tests=""
          
          for i in {1..5}; do
            if [ -f "test-${i}-success" ]; then
              passed_tests+="- Test Run $i ✅\n"
            elif [ -f "test-${i}-failure" ]; then
              failed_tests+="- Test Run $i ❌\n"
              echo "::warning::Test Run $i Failed"
            else
              echo "::warning::Test Run $i Status Unknown"
            fi
          done
          
          # Show results
          echo ""
          echo "===== Test Results ====="
          echo "Total tests: 5"
          echo "Passed: $success_count"
          echo "Failed: $failure_count"
          echo "Success rate: $((success_count * 100 / 5))%"
          
          echo -e "Passed Tests:\n$passed_tests"
          echo -e "Failed Tests:\n$failed_tests"
          
          echo "## Container-Copilot Integration Test Results" > $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "| --- | --- |" >> $GITHUB_STEP_SUMMARY
          echo "| Total Tests | 5 |" >> $GITHUB_STEP_SUMMARY
          echo "| Passed | $success_count |" >> $GITHUB_STEP_SUMMARY
          echo "| Failed | $failure_count |" >> $GITHUB_STEP_SUMMARY
          echo "| Success Rate | $((success_count * 100 / 5))% |" >> $GITHUB_STEP_SUMMARY
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Passed Tests" >> $GITHUB_STEP_SUMMARY
          if [ -n "$passed_tests" ]; then
            echo -e "$passed_tests" >> $GITHUB_STEP_SUMMARY
          else
            echo "None" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Failed Tests" >> $GITHUB_STEP_SUMMARY
          if [ -n "$failed_tests" ]; then
            echo -e "$failed_tests" >> $GITHUB_STEP_SUMMARY
          else
            echo "None" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Save values for other steps to use
          echo "success_count=$success_count" >> $GITHUB_OUTPUT
          echo "failure_count=$failure_count" >> $GITHUB_OUTPUT
          echo "success_rate=$((success_count * 100 / 5))" >> $GITHUB_OUTPUT
          
          # Clean up signal files
          rm -f test-*-success test-*-failure

      - name: Archive artifacts
        uses: actions/upload-artifact@v4
        with:
          name: container-copilot-artifacts
          path: coolstore/artifacts/
          retention-days: 14

      - name: Archive logs
        uses: actions/upload-artifact@v4
        with:
          name: container-copilot-logs
          path: coolstore/logs/
          retention-days: 14
          
      - name: Check success rate
        run: |
          success_count=${{ steps.container_copilot_runs.outputs.success_count }}
          
          # Fail the workflow if success rate is below 80%
          if [ $success_count -lt 4 ]; then
            echo "Success rate is below 80%, marking run as failed"
            exit 1