name: Integration Test

on:
  workflow_dispatch:
  pull_request:

# ensure that only one workflow is running at a time per branch/pr by canceling in-progress runs
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  setup:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout container-kit
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5 # v5.4.0
        with:
          go-version: "1.24"

      - name: Build container-kit
        run: |
          go build -o container-kit .

      - name: Upload binary
        uses: actions/upload-artifact@v4
        with:
          name: container-kit-binary
          path: container-kit
          retention-days: 1

  test-run:
    needs: setup
    runs-on: ubuntu-latest
    strategy:
      max-parallel: 25
      matrix:
        test-repo:
          - Azure-Samples/containerize-and-deploy-Java-app-to-Azure
          # - Azure-Samples/open-liberty-on-aks
          - Azure/wildfly-container-quickstart
          - Mariemfakhreldein/e-commerce-app
          - N-Usha/java-on-aks-piggymetrics
          - SaiUpadhyayula/SpringAngularEcommerce
          # - Zaaim-Halim/java-EE-E-Commerce-Web-App
          - agoncal/agoncal-application-petstore-ee7
          - aws-samples/aws-codedeploy-sample-tomcat
          - chamilad/tomcat-hello-world
          # - colinbut/monolith-enterprise-application
          - dhruvinrsoni/online-pizza-ordering-system
          - eNKay2408/Note-Taking
          # - jamesfalkner/jboss-daytrader
          - konveyor-ecosystem/coolstore
          # - kparent/jboss-helloworld
          # - oracle-samples/weblogic-examples
          # - shekhargulati/todoapp-forge
          # - spring-petclinic/spring-petclinic-microservices
        test-number: [1, 2, 3, 4, 5]
      fail-fast: false

    steps:
      - name: Download container-kit binary
        uses: actions/download-artifact@v4
        with:
          name: container-kit-binary
          path: ./

      - name: Make binary executable
        run: |
          chmod +x container-kit
          sudo mv container-kit /usr/local/bin/

      - name: Checkout Test Repo
        uses: actions/checkout@v4
        with:
          repository: ${{ matrix.test-repo }}
          path: test-repo

      - name: Setup Docker
        uses: docker/setup-buildx-action@v3

      - name: Install Kind
        uses: helm/kind-action@v1
        with:
          install_only: true

      - name: Run Test ${{ matrix.test-number }}
        id: run_test
        continue-on-error: true
        env:
          AZURE_OPENAI_KEY: ${{ secrets.AZURE_OPENAI_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
          AZURE_OPENAI_DEPLOYMENT_ID: ${{ secrets.AZURE_OPENAI_DEPLOYMENT_ID }}
        run: |
          cd test-repo

          # Make sure we have a place to store logs
          mkdir -p artifacts/logs

          # The success message we're looking for in the output
          SUCCESS_MESSAGE="🎉 All stages completed successfully!"

          # Start with a clean slate
          rm -f Dockerfile || true
          rm -rf manifests || true
          mkdir -p manifests

          # Run the test and save output
          REPO_NAME_WITHOUT_SLASH=$(echo "${{ matrix.test-repo }}" | sed 's|/|.|g' )
          RUN_NAME="$REPO_NAME_WITHOUT_SLASH#${{ matrix.test-number }}"
          #Output the run name for the next step
          echo "run_name=$RUN_NAME" >> $GITHUB_OUTPUT

          echo "Running container-kit generate for test $RUN_NAME ..."
          container-kit generate . --snapshot > "artifacts/logs/run-${RUN_NAME}.log" 2>&1

          # Save the files it created for successful tests
          if [ -f "Dockerfile" ] || [ -d "manifests" ]; then
            [ -f Dockerfile ] && cp Dockerfile artifacts/ || echo "No Dockerfile created"
            [ -d manifests ] && [ "$(ls -A manifests)" ] && cp -r manifests/* artifacts/ || echo "No manifests created"
          fi

          if grep -q "context deadline exceeded" "artifacts/logs/run-${RUN_NAME}.log"; then
            echo "❌ Test Run $RUN_NAME: Operation timed out - context deadline exceeded"
            echo "result=timeout" >> $GITHUB_OUTPUT
          elif grep -q "$SUCCESS_MESSAGE" "artifacts/logs/run-${RUN_NAME}.log"; then
            echo "✅ Test Run $RUN_NAME PASSED - Found '$SUCCESS_MESSAGE'"
            echo "result=success" >> $GITHUB_OUTPUT
          else
            echo "❌ Test Run $RUN_NAME: FAILED - Did not find '$SUCCESS_MESSAGE'"
            echo "result=failure" >> $GITHUB_OUTPUT
          fi

      - name: Save result
        if: always()
        run: |
          # Copy snapshot files to run artifacts if they exist
          if [ -d "test-repo/.container-kit" ]; then
            cp -r test-repo/.container-kit test-repo/artifacts/snapshot
          else
            echo "No .container-kit directory found - skipping snapshot copy"
          fi
          echo "${{ steps.run_test.outputs.result }}" > test-repo/artifacts/result.txt

      - name: Check Artifact Directory Size
        run: |
          max_size_bytes=$((20 * 1024 * 1024))  # 20 MiB in bytes
          echo "Max Artifact Directory Size: $max_size_bytes bytes"
          size_in_bytes=$(du -sb test-repo/artifacts/ | cut -f1)
          echo "Artifact Directory Size in bytes: $size_in_bytes"
          if [ "$size_in_bytes" -gt "$max_size_bytes" ]; then
            echo "❌ Artifact Directory Size $size_in_bytes exceeds $max_size_bytes"
            exit 1
          fi

      - name: Upload test artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: cc-run-${{ steps.run_test.outputs.run_name }}
          path: test-repo/artifacts/
          retention-days: 14

  aggregate-results:
    needs: test-run
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Download all results
        uses: actions/download-artifact@v4
        with:
          pattern: cc-run-*
          path: results

      - name: Integration Test Results Summary
        id: aggregate_results
        run: |
          tests_per_repo=5

          github_summary_table=""
          echo "## Container-Kit Integration Test Results" > $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          github_summary_table+="| Repo | Status | Success Rate | Passed | Failed | Timed Out |
          "
          github_summary_table+="| --- | --- | --- | --- | --- | --- |
          "

          # List repos without numbers
          export REPOS="$(ls results | grep -oP 'cc-run-\K[^#]+' | uniq)"
          echo "Repos: $REPOS"

          success_rates=()

          single_run_pass_threshold=30
          single_run_green_threshold=80

          # Loop through repos
          for repo in $REPOS; do
            echo "Processing results for $repo"

            # Count successes and failures
            success_count=0
            failure_count=0

            # Build detailed results
            passed_tests=""
            failed_tests="" # includes failed and timed out tests
            timedout_test_count=0

            # Loop through test runs
            for ((i=1; i<=$tests_per_repo; i++)); do
              if [ -f "results/cc-run-$repo#$i/result.txt" ]; then
                result=$(cat "results/cc-run-$repo#$i/result.txt")
                if [ "$result" == "success" ]; then
                  success_count=$((success_count + 1))
                  passed_tests+="- Test Run $i ✅\n"
                else
                  if [ "$result" == "timeout" ]; then
                    timedout_test_count=$((timedout_test_count + 1))
                  else
                    failure_count=$((failure_count + 1))
                    failed_tests+="- Test Run $i ❌\n"
                    echo "::warning::Test Run $i Failed"
                  fi
                fi
              else
                echo "::warning::Test Run $repo#$i Result Not Found"
              fi
            done

            success_rate=$((success_count * 100 / tests_per_repo))
            completed_tests=$((success_count + failure_count))

            success_emote=""
            if [ $success_rate -ge $single_run_green_threshold ]; then
              success_emote="✅"
            elif [ $success_rate -ge $single_run_pass_threshold ]; then
              success_emote="⚠️"
            else
              success_emote="❌"
            fi

            # Show results
            echo ""
            echo "===== $repo Test Results ====="
            echo "Total tests: $tests_per_repo"
            echo "Passed: $success_count"
            echo "Failed: $failure_count"
            echo "Timed out: $timedout_test_count"
            echo "Success rate: $success_rate%"

            # Convert the repo name back to GitHub URL format (replace dots with slashes)
            repo_url=$(echo "$repo" | sed 's/\./\//g')
            repo_markdown_link="[$repo_url](https://github.com/$repo_url)"
            github_summary_table+="| $repo_markdown_link | $success_emote | $success_rate% | $success_count | $failure_count | $timedout_test_count |
            "
            echo ""
            success_rates+=("$success_rate")
          done

          pass_threshold=50
          green_threshold=80
          average_success_rate=0
          for rate in "${success_rates[@]}"; do
            average_success_rate=$((average_success_rate + rate))
          done
          average_success_rate=$((average_success_rate / ${#success_rates[@]}))
          pass_rate_message=""
          if [ $average_success_rate -ge green_threshold ]; then
            pass_rate_message="✅ Average success rate: $average_success_rate% >= $green_threshold%"
          elif [ $average_success_rate -ge $pass_threshold ]; then
            pass_rate_message="⚠️ Average success rate: $average_success_rate% >= $pass_threshold%"
          else
            pass_rate_message="❌ Average success rate: $average_success_rate% < $pass_threshold%"
          fi
          echo "$pass_rate_message"
          echo "" >> $GITHUB_STEP_SUMMARY # add a blank line to separate the summary from the table
          echo "$pass_rate_message" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Output the summary table
          echo "$github_summary_table" >> $GITHUB_STEP_SUMMARY

          #last check to fail the job if the average success rate is below the threshold
          if [ $average_success_rate -lt $pass_threshold ]; then
            echo "Average success rate: $average_success_rate% < $pass_threshold%"
            exit 1
          fi
